{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoMiH19QDpVf"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "import torch\n",
        "import json\n",
        "from transformers import XLMRobertaTokenizerFast\n",
        "import argparse\n",
        "import os\n",
        "import logging\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(message)s', level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Constants - should match those used in training\n",
        "MAX_SEQ_LENGTH = 512\n",
        "NUM_LABELS_SPAN = 3  # 0:O, 1:B, 2:I\n",
        "NUM_LABELS_POLARITY = 4  # Positive, Negative, Neutral, None\n",
        "NUM_LABELS_INTENSITY = 3  # Strong, Average, Weak\n",
        "SPAN_EMBEDDING_DIM = 768\n",
        "RELATION_EMBEDDING_DIM = 256\n",
        "ADAPTER_SIZE = 128\n",
        "\n",
        "# Import or redefine necessary model classes\n",
        "# You should copy all the necessary model classes here from the original code\n",
        "# For brevity, I'll assume the StructuredSentimentModel and all its components are imported from a file\n",
        "\n",
        "from torch import nn\n",
        "\n",
        "# Neural network modules\n",
        "class SelfAttentionLayer(nn.Module):\n",
        "    def __init__(self, input_dim, num_heads=8, head_dim=96):\n",
        "        super(SelfAttentionLayer, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = head_dim\n",
        "        self.query = nn.Linear(input_dim, num_heads * head_dim)\n",
        "        self.key = nn.Linear(input_dim, num_heads * head_dim)\n",
        "        self.value = nn.Linear(input_dim, num_heads * head_dim)\n",
        "        self.output_projection = nn.Linear(num_heads * head_dim, input_dim)\n",
        "        self.layer_norm = nn.LayerNorm(input_dim)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "        q = self.query(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        k = self.key(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        v = self.value(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        scores = torch.matmul(q, k.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
        "        if mask is not None:\n",
        "            mask = mask.unsqueeze(1).unsqueeze(2)\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "        attn_weights = torch.softmax(scores, dim=-1)\n",
        "        context = torch.matmul(attn_weights, v).transpose(1, 2).contiguous().view(batch_size, seq_len, self.num_heads * self.head_dim)\n",
        "        output = self.output_projection(context)\n",
        "        return self.layer_norm(output + x)\n",
        "\n",
        "class SpanDetector(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=256, num_labels=NUM_LABELS_SPAN):\n",
        "        super(SpanDetector, self).__init__()\n",
        "        self.hidden = nn.Linear(input_dim, hidden_dim)\n",
        "        self.activation = nn.ReLU()\n",
        "        self.classifier = nn.Linear(hidden_dim, num_labels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden(x)\n",
        "        x = self.activation(x)\n",
        "        return self.classifier(x)\n",
        "\n",
        "class CrossSpanAttention(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim=RELATION_EMBEDDING_DIM):\n",
        "        super(CrossSpanAttention, self).__init__()\n",
        "        self.attention = nn.MultiheadAttention(input_dim, num_heads=4, batch_first=True)\n",
        "        self.projection = nn.Linear(input_dim, output_dim)\n",
        "        self.layer_norm = nn.LayerNorm(output_dim)\n",
        "\n",
        "    def forward(self, spans, span_masks=None):\n",
        "        key_padding_mask = ~span_masks if span_masks is not None else None\n",
        "        context, _ = self.attention(spans, spans, spans, key_padding_mask=key_padding_mask)\n",
        "        output = self.projection(context)\n",
        "        return self.layer_norm(output)\n",
        "\n",
        "class RelationClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=256, num_labels=2):  # NUM_LABELS_RELATION\n",
        "        super(RelationClassifier, self).__init__()\n",
        "        self.hidden = nn.Linear(input_dim * 2, hidden_dim)\n",
        "        self.activation = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(hidden_dim, num_labels)\n",
        "\n",
        "    def forward(self, span_pairs):\n",
        "        x = self.hidden(span_pairs)\n",
        "        x = self.activation(x)\n",
        "        x = self.dropout(x)\n",
        "        return self.classifier(x)\n",
        "\n",
        "class PolarityClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=128, num_labels=NUM_LABELS_POLARITY):\n",
        "        super(PolarityClassifier, self).__init__()\n",
        "        self.hidden = nn.Linear(input_dim, hidden_dim)\n",
        "        self.activation = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(hidden_dim, num_labels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.dropout(x)\n",
        "        return self.classifier(x)\n",
        "\n",
        "class IntensityClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=128, num_labels=NUM_LABELS_INTENSITY):\n",
        "        super(IntensityClassifier, self).__init__()\n",
        "        self.hidden = nn.Linear(input_dim, hidden_dim)\n",
        "        self.activation = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(hidden_dim, num_labels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.dropout(x)\n",
        "        return self.classifier(x)\n",
        "\n",
        "class LanguageAdapter(nn.Module):\n",
        "    def __init__(self, input_dim, bottleneck_dim=ADAPTER_SIZE):\n",
        "        super(LanguageAdapter, self).__init__()\n",
        "        self.down_project = nn.Linear(input_dim, bottleneck_dim)\n",
        "        self.activation = nn.ReLU()\n",
        "        self.up_project = nn.Linear(bottleneck_dim, input_dim)\n",
        "        self.layer_norm = nn.LayerNorm(input_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = self.down_project(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.up_project(x)\n",
        "        return self.layer_norm(x + residual)\n",
        "\n",
        "# Main model class\n",
        "class StructuredSentimentModel(nn.Module):\n",
        "    def __init__(self, pretrained_model_name=\"xlm-roberta-base\", use_adapters=False, num_languages=8):\n",
        "        super(StructuredSentimentModel, self).__init__()\n",
        "        from transformers import XLMRobertaModel\n",
        "        self.encoder = XLMRobertaModel.from_pretrained(pretrained_model_name)\n",
        "        self.hidden_size = self.encoder.config.hidden_size\n",
        "        self.span_attention = SelfAttentionLayer(self.hidden_size)\n",
        "        self.holder_detector = SpanDetector(self.hidden_size)\n",
        "        self.target_detector = SpanDetector(self.hidden_size)\n",
        "        self.expression_detector = SpanDetector(self.hidden_size)\n",
        "        self.cross_span_attention = CrossSpanAttention(self.hidden_size)\n",
        "        self.relation_classifier = RelationClassifier(RELATION_EMBEDDING_DIM)\n",
        "        self.polarity_classifier = PolarityClassifier(RELATION_EMBEDDING_DIM)\n",
        "        self.intensity_classifier = IntensityClassifier(RELATION_EMBEDDING_DIM)\n",
        "        self.use_adapters = use_adapters\n",
        "        if use_adapters:\n",
        "            self.language_adapters = nn.ModuleList([LanguageAdapter(self.hidden_size) for _ in range(num_languages)])\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        modules = [self.span_attention, self.holder_detector, self.target_detector,\n",
        "                   self.expression_detector, self.cross_span_attention,\n",
        "                   self.relation_classifier, self.polarity_classifier, self.intensity_classifier]\n",
        "        for module in modules:\n",
        "            for name, param in module.named_parameters():\n",
        "                if 'weight' in name and len(param.shape) >= 2:\n",
        "                    nn.init.xavier_uniform_(param)\n",
        "                elif 'bias' in name:\n",
        "                    nn.init.zeros_(param)\n",
        "\n",
        "    def extract_spans(self, span_logits, attention_mask):\n",
        "        batch_size = span_logits.size(0)\n",
        "        span_preds = torch.argmax(torch.softmax(span_logits, dim=-1), dim=-1)\n",
        "        all_spans = []\n",
        "        for i in range(batch_size):\n",
        "            mask = attention_mask[i].bool()\n",
        "            preds = span_preds[i][mask]\n",
        "            spans = []\n",
        "            start_idx = None\n",
        "            for j, label in enumerate(preds):\n",
        "                if label == 1:  # B\n",
        "                    if start_idx is not None:\n",
        "                        spans.append((start_idx, j - 1))\n",
        "                    start_idx = j\n",
        "                elif label == 0:  # O\n",
        "                    if start_idx is not None:\n",
        "                        spans.append((start_idx, j - 1))\n",
        "                        start_idx = None\n",
        "                elif label == 2:  # I\n",
        "                    if start_idx is None:\n",
        "                        start_idx = j\n",
        "            if start_idx is not None:\n",
        "                spans.append((start_idx, len(preds) - 1))\n",
        "            all_spans.append(spans)\n",
        "        return all_spans\n",
        "\n",
        "    def get_span_embeddings(self, hidden_states, spans, attention_mask):\n",
        "        batch_size = hidden_states.size(0)\n",
        "        max_spans = max([len(s) for s in spans], default=0)\n",
        "        if max_spans == 0:\n",
        "            return torch.zeros((batch_size, 0, self.hidden_size), device=hidden_states.device), torch.zeros((batch_size, 0), dtype=torch.bool, device=hidden_states.device)\n",
        "        span_embeddings = torch.zeros((batch_size, max_spans, self.hidden_size), device=hidden_states.device)\n",
        "        span_masks = torch.zeros((batch_size, max_spans), dtype=torch.bool, device=hidden_states.device)\n",
        "        for i in range(batch_size):\n",
        "            for j, (start, end) in enumerate(spans[i]):\n",
        "                if j < max_spans:\n",
        "                    span_embeddings[i, j] = hidden_states[i, start:end+1].mean(dim=0)\n",
        "                    span_masks[i, j] = True\n",
        "        return span_embeddings, span_masks\n",
        "\n",
        "    def _combine_spans(self, holder_emb, holder_mask, target_emb, target_mask, expr_emb, expr_mask):\n",
        "        batch_size = holder_emb.size(0)\n",
        "        max_spans = holder_emb.size(1) + target_emb.size(1) + expr_emb.size(1)\n",
        "        if max_spans == 0:\n",
        "            return torch.zeros((batch_size, 0, self.hidden_size), device=holder_emb.device), torch.zeros((batch_size, 0), dtype=torch.bool, device=holder_emb.device)\n",
        "        combined_emb = torch.zeros((batch_size, max_spans, self.hidden_size), device=holder_emb.device)\n",
        "        combined_mask = torch.zeros((batch_size, max_spans), dtype=torch.bool, device=holder_emb.device)\n",
        "        holder_size = holder_emb.size(1)\n",
        "        target_size = target_emb.size(1)\n",
        "        expr_size = expr_emb.size(1)\n",
        "        combined_emb[:, :holder_size] = holder_emb\n",
        "        combined_emb[:, holder_size:holder_size+target_size] = target_emb\n",
        "        combined_emb[:, holder_size+target_size:] = expr_emb\n",
        "        combined_mask[:, :holder_size] = holder_mask\n",
        "        combined_mask[:, holder_size:holder_size+target_size] = target_mask\n",
        "        combined_mask[:, holder_size+target_size:] = expr_mask\n",
        "        return combined_emb, combined_mask\n",
        "\n",
        "    def _create_span_pairs(self, span_embeddings, holder_mask, target_mask, expr_mask):\n",
        "        batch_size = span_embeddings.size(0)\n",
        "        holder_size = holder_mask.size(1)\n",
        "        target_size = target_mask.size(1)\n",
        "        expr_size = expr_mask.size(1)\n",
        "        total_holders = holder_mask.sum(dim=1)\n",
        "        total_targets = target_mask.sum(dim=1)\n",
        "        total_expressions = expr_mask.sum(dim=1)\n",
        "        max_pairs = torch.max(total_holders * total_expressions + total_targets * total_expressions)\n",
        "        if max_pairs == 0:\n",
        "            return None, None\n",
        "        pair_embeddings = torch.zeros((batch_size, max_pairs, RELATION_EMBEDDING_DIM * 2), device=span_embeddings.device)\n",
        "        pair_indices = torch.zeros((batch_size, max_pairs, 2), dtype=torch.long, device=span_embeddings.device)\n",
        "        offset = holder_size + target_size\n",
        "        for i in range(batch_size):\n",
        "            pair_idx = 0\n",
        "            for h_idx in range(holder_size):\n",
        "                if not holder_mask[i, h_idx]:\n",
        "                    continue\n",
        "                for e_idx in range(expr_size):\n",
        "                    if not expr_mask[i, e_idx] or pair_idx >= max_pairs:\n",
        "                        continue\n",
        "                    pair_embeddings[i, pair_idx] = torch.cat([span_embeddings[i, h_idx], span_embeddings[i, offset + e_idx]])\n",
        "                    pair_indices[i, pair_idx] = torch.tensor([h_idx, offset + e_idx], device=span_embeddings.device)\n",
        "                    pair_idx += 1\n",
        "            for t_idx in range(target_size):\n",
        "                if not target_mask[i, t_idx]:\n",
        "                    continue\n",
        "                for e_idx in range(expr_size):\n",
        "                    if not expr_mask[i, e_idx] or pair_idx >= max_pairs:\n",
        "                        continue\n",
        "                    pair_embeddings[i, pair_idx] = torch.cat([span_embeddings[i, holder_size + t_idx], span_embeddings[i, offset + e_idx]])\n",
        "                    pair_indices[i, pair_idx] = torch.tensor([holder_size + t_idx, offset + e_idx], device=span_embeddings.device)\n",
        "                    pair_idx += 1\n",
        "        return pair_embeddings, pair_indices\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, language_id=None, labels=None):\n",
        "        batch_size = input_ids.size(0)\n",
        "        encoder_outputs = self.encoder(input_ids, attention_mask=attention_mask)\n",
        "        hidden_states = encoder_outputs.last_hidden_state\n",
        "\n",
        "        if self.use_adapters and language_id is not None:\n",
        "            adapted_states = torch.zeros_like(hidden_states)\n",
        "            for i in range(batch_size):\n",
        "                adapted_states[i] = self.language_adapters[language_id[i].item()](hidden_states[i])\n",
        "            hidden_states = adapted_states\n",
        "\n",
        "        span_aware_states = self.span_attention(hidden_states, attention_mask)\n",
        "        holder_logits = self.holder_detector(span_aware_states)\n",
        "        target_logits = self.target_detector(span_aware_states)\n",
        "        expression_logits = self.expression_detector(span_aware_states)\n",
        "\n",
        "        if labels is not None:\n",
        "            # Training mode - omitted for inference script\n",
        "            pass\n",
        "        else:\n",
        "            # Inference mode\n",
        "            holder_spans = self.extract_spans(holder_logits, attention_mask)\n",
        "            target_spans = self.extract_spans(target_logits, attention_mask)\n",
        "            expression_spans = self.extract_spans(expression_logits, attention_mask)\n",
        "            holder_embeddings, holder_masks = self.get_span_embeddings(span_aware_states, holder_spans, attention_mask)\n",
        "            target_embeddings, target_masks = self.get_span_embeddings(span_aware_states, target_spans, attention_mask)\n",
        "            expression_embeddings, expression_masks = self.get_span_embeddings(span_aware_states, expression_spans, attention_mask)\n",
        "            all_span_embeddings, all_span_masks = self._combine_spans(holder_embeddings, holder_masks, target_embeddings, target_masks, expression_embeddings, expression_masks)\n",
        "            relation_aware_embeddings = self.cross_span_attention(all_span_embeddings, all_span_masks)\n",
        "            relation_pairs, pair_indices = self._create_span_pairs(relation_aware_embeddings, holder_masks, target_masks, expression_masks)\n",
        "\n",
        "            relation_logits = None\n",
        "            polarity_logits = None\n",
        "            intensity_logits = None\n",
        "            if relation_pairs is not None:\n",
        "                relation_logits = self.relation_classifier(relation_pairs)\n",
        "                expression_relation_aware = relation_aware_embeddings[:, holder_embeddings.size(1) + target_embeddings.size(1):, :]\n",
        "                polarity_logits = self.polarity_classifier(expression_relation_aware)\n",
        "                intensity_logits = self.intensity_classifier(expression_relation_aware)\n",
        "\n",
        "            return {\n",
        "                'holder_logits': holder_logits,\n",
        "                'target_logits': target_logits,\n",
        "                'expression_logits': expression_logits,\n",
        "                'relation_logits': relation_logits,\n",
        "                'polarity_logits': polarity_logits,\n",
        "                'intensity_logits': intensity_logits,\n",
        "                'holder_spans': holder_spans,\n",
        "                'target_spans': target_spans,\n",
        "                'expression_spans': expression_spans,\n",
        "                'pair_indices': pair_indices\n",
        "            }\n",
        "\n",
        "class SentimentAnalyzer:\n",
        "    def __init__(self, model_path, pretrained_model=\"xlm-roberta-base\", device=None):\n",
        "        \"\"\"\n",
        "        Initialize the sentiment analyzer with a trained model\n",
        "\n",
        "        Args:\n",
        "            model_path: Path to the saved model checkpoint\n",
        "            pretrained_model: Name of the pretrained model used during training\n",
        "            device: Device to run inference on (cuda or cpu)\n",
        "        \"\"\"\n",
        "        if device is None:\n",
        "            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        else:\n",
        "            self.device = device\n",
        "\n",
        "        logger.info(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Load tokenizer\n",
        "        self.tokenizer = XLMRobertaTokenizerFast.from_pretrained(pretrained_model)\n",
        "\n",
        "        # Initialize model\n",
        "        self.model = StructuredSentimentModel(pretrained_model_name=pretrained_model)\n",
        "\n",
        "        # Load trained weights\n",
        "        checkpoint = torch.load(model_path, map_location=self.device)\n",
        "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "\n",
        "        logger.info(f\"Model loaded from {model_path}\")\n",
        "\n",
        "        # Define polarity and intensity mappings\n",
        "        self.polarity_map = {0: \"Positive\", 1: \"Negative\", 2: \"Neutral\", 3: \"None\"}\n",
        "        self.intensity_map = {0: \"Strong\", 1: \"Average\", 2: \"Weak\"}\n",
        "        # Define BIO labels for easier interpretation\n",
        "        self.bio_labels = {0: \"O\", 1: \"B\", 2: \"I\"}\n",
        "\n",
        "    def _get_actual_text_spans(self, text, tokens, spans):\n",
        "        \"\"\"\n",
        "        Convert token indices to character spans in the original text\n",
        "\n",
        "        Args:\n",
        "            text: Original text\n",
        "            tokens: Tokenized text info\n",
        "            spans: List of (start_token, end_token) tuples\n",
        "\n",
        "        Returns:\n",
        "            List of (start_char, end_char, text_span) tuples\n",
        "        \"\"\"\n",
        "        text_spans = []\n",
        "        offset_mapping = tokens.offset_mapping[0].tolist()\n",
        "\n",
        "        for start_token, end_token in spans:\n",
        "            if start_token >= len(offset_mapping) or end_token >= len(offset_mapping):\n",
        "                continue\n",
        "\n",
        "            start_char = offset_mapping[start_token][0]\n",
        "            end_char = offset_mapping[end_token][1]\n",
        "\n",
        "            if start_char < end_char and end_char <= len(text):\n",
        "                span_text = text[start_char:end_char]\n",
        "                text_spans.append((start_char, end_char, span_text))\n",
        "\n",
        "        return text_spans\n",
        "\n",
        "    def _get_bio_encoding(self, holder_logits, target_logits, expression_logits, attention_mask):\n",
        "        \"\"\"\n",
        "        Convert logits to BIO labels for visualization\n",
        "\n",
        "        Args:\n",
        "            holder_logits: Predicted logits for holder spans\n",
        "            target_logits: Predicted logits for target spans\n",
        "            expression_logits: Predicted logits for expression spans\n",
        "            attention_mask: Attention mask to filter out padding tokens\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with BIO encodings for each entity type\n",
        "        \"\"\"\n",
        "        # Get the predicted BIO labels\n",
        "        holder_preds = torch.argmax(holder_logits, dim=-1)[0].cpu().numpy()\n",
        "        target_preds = torch.argmax(target_logits, dim=-1)[0].cpu().numpy()\n",
        "        expression_preds = torch.argmax(expression_logits, dim=-1)[0].cpu().numpy()\n",
        "\n",
        "        # Get active token indices (non-padding)\n",
        "        active_indices = attention_mask[0].cpu().numpy().nonzero()[0]\n",
        "\n",
        "        # Map indices to BIO labels\n",
        "        holder_bio = [self.bio_labels[holder_preds[i]] for i in active_indices]\n",
        "        target_bio = [self.bio_labels[target_preds[i]] for i in active_indices]\n",
        "        expression_bio = [self.bio_labels[expression_preds[i]] for i in active_indices]\n",
        "\n",
        "        return {\n",
        "            \"holder_bio\": holder_bio,\n",
        "            \"target_bio\": target_bio,\n",
        "            \"expression_bio\": expression_bio\n",
        "        }\n",
        "\n",
        "    def analyze(self, text):\n",
        "        \"\"\"\n",
        "        Analyze a text for structured sentiment\n",
        "\n",
        "        Args:\n",
        "            text: Text to analyze\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with sentiment analysis results\n",
        "        \"\"\"\n",
        "        # Tokenize input\n",
        "        tokens = self.tokenizer(\n",
        "            text,\n",
        "            max_length=MAX_SEQ_LENGTH,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_offsets_mapping=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        input_ids = tokens['input_ids'].to(self.device)\n",
        "        attention_mask = tokens['attention_mask'].to(self.device)\n",
        "\n",
        "        # Get model predictions\n",
        "        with torch.no_grad():\n",
        "            # Get the encoder outputs directly from XLM-RoBERTa\n",
        "            encoder_outputs = self.model.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            embeddings = encoder_outputs.last_hidden_state\n",
        "\n",
        "            # Full model inference\n",
        "            outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Extract spans\n",
        "        holder_spans = outputs['holder_spans'][0]\n",
        "        target_spans = outputs['target_spans'][0]\n",
        "        expression_spans = outputs['expression_spans'][0]\n",
        "\n",
        "        # Get character spans from token spans\n",
        "        holder_text_spans = self._get_actual_text_spans(text, tokens, holder_spans)\n",
        "        target_text_spans = self._get_actual_text_spans(text, tokens, target_spans)\n",
        "        expression_text_spans = self._get_actual_text_spans(text, tokens, expression_spans)\n",
        "\n",
        "        # Get BIO encodings\n",
        "        bio_encodings = self._get_bio_encoding(\n",
        "            outputs['holder_logits'],\n",
        "            outputs['target_logits'],\n",
        "            outputs['expression_logits'],\n",
        "            attention_mask\n",
        "        )\n",
        "\n",
        "        # Get polarity and intensity for expressions\n",
        "        sentiment_opinions = []\n",
        "\n",
        "        if outputs['polarity_logits'] is not None and outputs['intensity_logits'] is not None:\n",
        "            polarity_preds = torch.argmax(outputs['polarity_logits'], dim=-1)\n",
        "            intensity_preds = torch.argmax(outputs['intensity_logits'], dim=-1)\n",
        "\n",
        "            num_expressions = min(len(expression_text_spans), polarity_preds.size(1))\n",
        "\n",
        "            for i in range(num_expressions):\n",
        "                polarity_idx = polarity_preds[0, i].item()\n",
        "                intensity_idx = intensity_preds[0, i].item()\n",
        "\n",
        "                opinion = {\n",
        "                    \"expression\": expression_text_spans[i][2],\n",
        "                    \"expression_span\": f\"{expression_text_spans[i][0]}:{expression_text_spans[i][1]}\",\n",
        "                    \"polarity\": self.polarity_map[polarity_idx],\n",
        "                    \"intensity\": self.intensity_map[intensity_idx],\n",
        "                }\n",
        "\n",
        "                # Find related holder and target (if available)\n",
        "                if outputs['pair_indices'] is not None:\n",
        "                    for pair_idx in range(outputs['pair_indices'].size(1)):\n",
        "                        idx1, idx2 = outputs['pair_indices'][0, pair_idx]\n",
        "\n",
        "                        # If this pair involves the current expression\n",
        "                        expr_offset = len(holder_spans) + len(target_spans)\n",
        "\n",
        "                        if idx2 == expr_offset + i:\n",
        "                            # It's a holder-expression or target-expression pair\n",
        "                            if idx1 < len(holder_spans):\n",
        "                                # It's a holder\n",
        "                                holder_idx = idx1.item()\n",
        "                                if holder_idx < len(holder_text_spans):\n",
        "                                    opinion[\"holder\"] = holder_text_spans[holder_idx][2]\n",
        "                                    opinion[\"holder_span\"] = f\"{holder_text_spans[holder_idx][0]}:{holder_text_spans[holder_idx][1]}\"\n",
        "                            else:\n",
        "                                # It's a target\n",
        "                                target_idx = idx1.item() - len(holder_spans)\n",
        "                                if target_idx < len(target_text_spans):\n",
        "                                    opinion[\"target\"] = target_text_spans[target_idx][2]\n",
        "                                    opinion[\"target_span\"] = f\"{target_text_spans[target_idx][0]}:{target_text_spans[target_idx][1]}\"\n",
        "\n",
        "                # Add default values for missing fields\n",
        "                if \"holder\" not in opinion:\n",
        "                    opinion[\"holder\"] = \"\"\n",
        "                    opinion[\"holder_span\"] = \"0:0\"\n",
        "                if \"target\" not in opinion:\n",
        "                    opinion[\"target\"] = \"\"\n",
        "                    opinion[\"target_span\"] = \"0:0\"\n",
        "\n",
        "                sentiment_opinions.append(opinion)\n",
        "\n",
        "        # Prepare encoded embeddings info\n",
        "        # Get all active tokens\n",
        "        active_indices = attention_mask[0].cpu().numpy().nonzero()[0]\n",
        "        tokens_list = self.tokenizer.convert_ids_to_tokens(input_ids[0][active_indices].cpu().numpy())\n",
        "\n",
        "        # For each token, include the first few dimensions of its embedding\n",
        "        num_dims_to_show = 5  # Show first 5 dimensions for each token\n",
        "        embeddings_list = []\n",
        "\n",
        "        for idx in active_indices:\n",
        "            token_embedding = embeddings[0, idx, :num_dims_to_show].cpu().numpy().tolist()\n",
        "            embeddings_list.append(token_embedding)\n",
        "\n",
        "        # Also include the full embedding for the first token as an example\n",
        "        first_token_full_embedding = embeddings[0, active_indices[0], :].cpu().numpy().tolist()\n",
        "\n",
        "        embeddings_info = {\n",
        "            \"tokens\": tokens_list,\n",
        "            \"embeddings\": embeddings_list,  # First few dimensions for all tokens\n",
        "            \"first_token_full_embedding\": first_token_full_embedding,\n",
        "            \"embeddings_shape\": list(embeddings.shape),\n",
        "            \"num_dimensions_shown\": num_dims_to_show\n",
        "        }\n",
        "\n",
        "        return {\n",
        "            \"text\": text,\n",
        "            \"holders\": [span[2] for span in holder_text_spans],\n",
        "            \"targets\": [span[2] for span in target_text_spans],\n",
        "            \"expressions\": [span[2] for span in expression_text_spans],\n",
        "            \"opinions\": sentiment_opinions,\n",
        "            \"bio_encodings\": bio_encodings,\n",
        "            \"encoded_embeddings\": embeddings_info\n",
        "        }\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/NLP-Project/mpqa_best_model_f1_0.5422.pt\"  # ← update this\n",
        "pretrained_model = \"xlm-roberta-base\"\n",
        "text_to_analyze = \"राष्ट्रपति द्रौपदी मुर्मू ने राष्ट्र का अभिनंदन किया और देशवासियों से आग्रह किया कि वे सभी के जीवन को निरंतर प्रगति, समृद्धि और खुशहाली के रंगों से भर दें।\"\n",
        "input_file_path = None  # or set path to a file\n",
        "output_file_path = \"sentiment_analysis_results.json\"\n",
        "\n",
        "# Initialize analyzer\n",
        "analyzer = SentimentAnalyzer(model_path, pretrained_model)\n",
        "\n",
        "results = []\n",
        "\n",
        "# Analyze a single text\n",
        "if text_to_analyze:\n",
        "    analysis = analyzer.analyze(text_to_analyze)\n",
        "    results.append(analysis)\n",
        "\n",
        "    print(f\"\\nAnalysis for: '{text_to_analyze}'\")\n",
        "    print(f\"Holders: {analysis['holders']}\")\n",
        "    print(f\"Targets: {analysis['targets']}\")\n",
        "    print(f\"Expressions: {analysis['expressions']}\")\n",
        "\n",
        "    print(\"\\nOpinions:\")\n",
        "    for i, opinion in enumerate(analysis['opinions']):\n",
        "        print(f\"  Opinion {i+1}:\")\n",
        "        print(f\"    Holder: '{opinion['holder']}'\")\n",
        "        print(f\"    Target: '{opinion['target']}'\")\n",
        "        print(f\"    Expression: '{opinion['expression']}'\")\n",
        "        print(f\"    Polarity: {opinion['polarity']}\")\n",
        "        print(f\"    Intensity: {opinion['intensity']}\")\n",
        "\n",
        "    # Print BIO encodings\n",
        "    print(\"\\nBIO Encodings:\")\n",
        "    bio = analysis['bio_encodings']\n",
        "\n",
        "    # Get tokens aligned with BIO tags\n",
        "    tokens = analysis['encoded_embeddings']['tokens']\n",
        "\n",
        "    print(\"\\nToken\\t\\tHolder\\tTarget\\tExpression\")\n",
        "    print(\"-\" * 50)\n",
        "    for i, token in enumerate(tokens):\n",
        "        # Format to align columns\n",
        "        token_str = token[:10] + \"...\" if len(token) > 10 else token\n",
        "        token_str = token_str.ljust(15)\n",
        "        print(f\"{token_str}\\t{bio['holder_bio'][i]}\\t{bio['target_bio'][i]}\\t{bio['expression_bio'][i]}\")\n",
        "\n",
        "    # Print embeddings information\n",
        "    emb_info = analysis['encoded_embeddings']\n",
        "    print(\"\\nEncoded Embeddings (XLM-RoBERTa):\")\n",
        "    print(f\"Embeddings shape: {emb_info['embeddings_shape']} (batch, sequence_length, hidden_dim)\")\n",
        "    print(f\"\\nShowing first {emb_info['num_dimensions_shown']} dimensions for each token:\")\n",
        "\n",
        "    print(\"\\nToken\\t\\tEmbedding dimensions (first few)\")\n",
        "    print(\"-\" * 70)\n",
        "    for i, token in enumerate(emb_info['tokens']):\n",
        "        token_str = token[:10] + \"...\" if len(token) > 10 else token\n",
        "        token_str = token_str.ljust(15)\n",
        "        emb_str = \"[\" + \", \".join([f\"{val:.4f}\" for val in emb_info['embeddings'][i]]) + \", ...]\"\n",
        "        print(f\"{token_str}\\t{emb_str}\")\n",
        "\n",
        "    # Print a full example embedding for reference\n",
        "    print(\"\\nExample of full embedding vector for first token:\")\n",
        "    first_token = emb_info['tokens'][0]\n",
        "    print(f\"Token: {first_token}\")\n",
        "\n",
        "    # Print the full embedding in a readable format (chunked)\n",
        "    full_emb = emb_info['first_token_full_embedding']\n",
        "    chunk_size = 10\n",
        "    for i in range(0, len(full_emb), chunk_size):\n",
        "        chunk = full_emb[i:i+chunk_size]\n",
        "        print(f\"Dims {i}-{i+len(chunk)-1}: \" + \", \".join([f\"{val:.4f}\" for val in chunk]))\n",
        "\n",
        "# Or analyze from a file\n",
        "elif input_file_path:\n",
        "    with open(input_file_path, 'r', encoding='utf-8') as f:\n",
        "        texts = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "    for text in texts:\n",
        "        try:\n",
        "            analysis = analyzer.analyze(text)\n",
        "            results.append(analysis)\n",
        "        except Exception as e:\n",
        "            print(f\"Error analyzing text: {text}\")\n",
        "            print(str(e))\n",
        "\n",
        "# Save results\n",
        "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"\\n✅ Results saved to: {output_file_path}\")"
      ]
    }
  ]
}